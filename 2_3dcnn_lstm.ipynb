{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_Hq8ITtecihn"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import imutils\n",
    "import dlib \n",
    "import cv2 \n",
    "import imageio.v2 as imageio\n",
    "from imutils import face_utils\n",
    "from skimage.transform import resize\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = ['F01','F02','F04','F05','F06','F07','F08','F09', 'F10','F11','M01','M02','M04','M07','M08']\n",
    "data_types = ['words']\n",
    "folder_enum = ['01','02','03','04','05','06','07','08', '09', '10']\n",
    "instances = ['01','02','03','04','05','06','07','08', '09', '10']\n",
    "\n",
    "words = ['Begin', 'Choose', 'Connection', 'Navigation', 'Next', 'Previous', 'Start', 'Stop', 'Hello', 'Web']          \n",
    "words_di = {i:words[i] for i in range(len(words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 22\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "MAX_WIDTH = 100\n",
    "MAX_HEIGHT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_30204\\2629557079.py:25: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(path + '/' + img_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading images for person F01. Time taken : 2.1898748874664307 secs.\n",
      "Finished reading images for person F02. Time taken : 2.0407867431640625 secs.\n",
      "Finished reading images for person F04. Time taken : 4.069188356399536 secs.\n",
      "Finished reading images for person F05. Time taken : 3.6780033111572266 secs.\n",
      "Finished reading images for person F06. Time taken : 3.664707899093628 secs.\n",
      "Finished reading images for person F07. Time taken : 3.0289440155029297 secs.\n",
      "Finished reading images for person F08. Time taken : 2.5199313163757324 secs.\n",
      "Finished reading images for person F09. Time taken : 2.5148324966430664 secs.\n",
      "Finished reading images for person F10. Time taken : 1.9978485107421875 secs.\n",
      "Finished reading images for person F11. Time taken : 2.1335208415985107 secs.\n",
      "Finished reading images for person M01. Time taken : 2.846742868423462 secs.\n",
      "Finished reading images for person M02. Time taken : 3.2498836517333984 secs.\n",
      "Finished reading images for person M04. Time taken : 2.874885082244873 secs.\n",
      "Finished reading images for person M07. Time taken : 2.3877272605895996 secs.\n",
      "Finished reading images for person M08. Time taken : 3.2333312034606934 secs.\n",
      "Time taken for creating constant size 3D Tensors from those cropped lip regions : 42.43320965766907 secs.\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "UNSEEN_VALIDATION_SPLIT = ['F07', 'M02']\n",
    "# UNSEEN_VALIDATION_SPLIT = ['F05']\n",
    "\n",
    "UNSEEN_TEST_SPLIT = ['F04']\n",
    "\n",
    "directory = r'cropped' \n",
    "\n",
    "for person_id in people:\n",
    "    tx1 = time.time()\n",
    "    for data_type in data_types:\n",
    "\n",
    "        # A for loop that iterates through the different words that are lip read by each person. for count, value in enumerate(values): \n",
    "        for word_index, word in enumerate(folder_enum):\n",
    "#             print(f\"Word : '{words[word_index]}'\")\n",
    "            for iteration in instances:\n",
    "                path = os.path.join(directory, person_id, data_type, word, iteration)\n",
    "#                 filelist = sorted(os.listdir(path + '/'))\n",
    "                filelist = sorted(os.listdir(path))\n",
    "                \n",
    "\n",
    "                sequence = [] \n",
    "                for img_name in filelist:\n",
    "                    if img_name.startswith('color'):\n",
    "                        image = imageio.imread(path + '/' + img_name)\n",
    "                        image = resize(image, (MAX_WIDTH, MAX_HEIGHT))\n",
    "                        \n",
    "                        # This is being done to convert a float-valued image (with values between 0 and 1) to an 8-bit grayscale image with values between 0 and 255.\n",
    "                        image = 255 * image\n",
    "                        # Convert to integer data type pixels.\n",
    "                        image = image.astype(np.uint8)\n",
    "                        sequence.append(image)        \n",
    "\n",
    "                # add zeros to remaining indeces \n",
    "                pad_array = [np.zeros((MAX_WIDTH, MAX_HEIGHT))]   #single image placeholder                       \n",
    "                sequence.extend(pad_array * (max_seq_length - len(sequence)))\n",
    "                sequence = np.array(sequence)\n",
    "                \n",
    "                # assign the sequence to repective splits\n",
    "                if person_id in UNSEEN_TEST_SPLIT:\n",
    "                    X_test.append(sequence)\n",
    "                    y_test.append(word_index)\n",
    "                elif person_id in UNSEEN_VALIDATION_SPLIT:\n",
    "                    X_val.append(sequence)\n",
    "                    y_val.append(word_index)\n",
    "                else:\n",
    "                    X_train.append(sequence)\n",
    "                    y_train.append(word_index)    \n",
    "    tx2 = time.time()\n",
    "    print(f'Finished reading images for person {person_id}. Time taken : {tx2 - tx1} secs.')    \n",
    "    \n",
    "t2 = time.time()\n",
    "print(f\"Time taken for creating constant size 3D Tensors from those cropped lip regions : {t2 - t1} secs.\")\n",
    "# A tensor is a multi-dimensional array that can store data of any type (integers, floating point values, etc.). In deep learning, tensors are used to store the data that is fed into the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 22, 100, 100)\n",
      "(200, 22, 100, 100)\n",
      "(100, 22, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200,)\n",
      "(200,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_it(X):\n",
    "    \n",
    "    # keepdims=True keeps same size as input. This is useful for broadcasting the result.\n",
    "    # Broadcasting is a technique in NumPy where it automatically expands an array \n",
    "    # with smaller dimensions to match the shape of an array with larger dimensions during element-wise operations.\n",
    "    # For example, in this case, if the shape of the filter was (22, 1, 1) instead of (1, 22, 1, 1),\n",
    "    #  the result of the convolution would not be broadcastable and an error would be raised. By having the shape (1, 22, 1, 1), \n",
    "    # it allows the result to be broadcast to (1200, 22, 1, 1), which is the shape of the output volume.\n",
    "    v_min = X.min(axis=(2, 3), keepdims=True) #op shape (1200, 22, 1, 1). \n",
    "    v_max = X.max(axis=(2, 3), keepdims=True)\n",
    "    X = (X - v_min)/(v_max - v_min)\n",
    "    X = np.nan_to_num(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils, generic_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_30204\\1818949968.py:11: RuntimeWarning: invalid value encountered in divide\n",
      "  X = (X - v_min)/(v_max - v_min)\n"
     ]
    }
   ],
   "source": [
    "X_train = normalize_it(X_train)\n",
    "X_val = normalize_it(X_val)\n",
    "X_test = normalize_it(X_test)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "y_val = np_utils.to_categorical(y_val, 10)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=0)\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=4)\n",
    "X_val = np.expand_dims(X_val, axis=4)\n",
    "X_test = np.expand_dims(X_test, axis=4) # op : (100, 22, 100, 100, 1)\n",
    "# This is often used when working with Convolutional Neural Networks (CNNs) to give them the correct data shape for processing.\n",
    "# This additional dimension can be interpreted as a channel dimension in case of image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('splits/X_train',X_train)\n",
    "np.save('splits/X_val',X_val)\n",
    "np.save('splits/X_test',X_test)\n",
    "np.save('splits/y_train',y_train)\n",
    "np.save('splits/y_val',y_val)\n",
    "np.save('splits/y_test',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LGARQ3ADbE-z"
   },
   "outputs": [],
   "source": [
    "\n",
    "splits = r'splits/'\n",
    "X_train = np.load(splits + 'X_train.npy')\n",
    "X_val = np.load(splits + 'X_val.npy')\n",
    "X_test = np.load(splits + 'X_test.npy')\n",
    "y_train = np.load(splits + 'y_train.npy')\n",
    "y_val = np.load(splits + 'y_val.npy')\n",
    "y_test = np.load(splits + 'y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JiS7LVpMcYCh"
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, ZeroPadding3D, TimeDistributed, LSTM, GRU, Reshape\n",
    "from keras.utils.vis_utils import plot_model\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2iD57qtvcZ-8",
    "outputId": "d94dd2e4-c715-44d6-982c-90f016cf61ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 20, 98, 98, 32)    896       \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 10, 49, 49, 32)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 8, 47, 47, 64)     55360     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 4, 23, 23, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 2, 21, 21, 128)    221312    \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 1, 10, 10, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 128, 100)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128, 32)           17024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128, 32)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              8390656   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,793,674\n",
      "Trainable params: 10,793,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st layer group\n",
    "model.add(Conv3D(32, (3, 3, 3), strides = 1, input_shape=(22, 100, 100, 1), activation='relu', padding='valid'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "model.add(Conv3D(64, (3, 3, 3), activation='relu', strides=1))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "model.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))\n",
    "\n",
    "# reshape layer\n",
    "# shape = model.get_output_shape_at(0)\n",
    "shape = model.layers[-1].output_shape\n",
    "\n",
    "# he reshaping is necessary for the LSTM layer because LSTM layers in \n",
    "# Keras require a 3D input with the shape of (batch_size, timesteps, features)\n",
    "model.add(Reshape((shape[-1],shape[1]*shape[2]*shape[3])))\n",
    "\n",
    "\n",
    "# LSTMS - Recurrent Network Layer\n",
    "# The \"return_sequences\" means that the output from this LSTM layer will be returned as a sequence.\n",
    "#  In other words, the output of each time step will be kept and passed on to the next layer.\n",
    "#  If \"return_sequences\" was set to False, only the final output of the LSTM layer will be returned.\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add((Flatten()))\n",
    "\n",
    "# # FC layers group\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "from PIL import ImageFont\n",
    "\n",
    "font = ImageFont.truetype(\"arial.ttf\", 32)  # using comic sans is strictly prohibited!\n",
    "visualkeras.layered_view(model, legend=True, font=font, spacing=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3wpP0q5cqJW",
    "outputId": "562d507f-ec08-433c-8ec7-c7b97c217f70"
   },
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=45, batch_size= 16)\n",
    "t2 = time.time()\n",
    "print()\n",
    "print(f\"Training time : {t2 - t1} secs.\")\n",
    "\n",
    "model.save('lip_model_cnn_lstm.h5')\n",
    "model.save_weights('lip_model_cnn_lstm_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "savedModel = load_model('lip_model_cnn_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 1s/step\n"
     ]
    }
   ],
   "source": [
    "ypred = savedModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_words = [words[i] for i in np.argmax(ypred, axis=1)]\n",
    "actual_words = [words[i] for i in np.argmax(y_test, axis=1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : Hello \t Actual : Connection\n",
      "Predicted : Previous \t Actual : Hello\n",
      "Predicted : Begin \t Actual : Begin\n",
      "Predicted : Navigation \t Actual : Previous\n",
      "Predicted : Stop \t Actual : Stop\n",
      "Predicted : Stop \t Actual : Web\n",
      "Predicted : Choose \t Actual : Choose\n",
      "Predicted : Stop \t Actual : Stop\n",
      "Predicted : Navigation \t Actual : Previous\n",
      "Predicted : Navigation \t Actual : Web\n",
      "Predicted : Navigation \t Actual : Previous\n",
      "Predicted : Navigation \t Actual : Web\n",
      "Predicted : Stop \t Actual : Stop\n",
      "Predicted : Choose \t Actual : Choose\n",
      "Predicted : Begin \t Actual : Begin\n",
      "Predicted : Previous \t Actual : Navigation\n",
      "Predicted : Start \t Actual : Connection\n",
      "Predicted : Stop \t Actual : Connection\n",
      "Predicted : Navigation \t Actual : Navigation\n",
      "Predicted : Connection \t Actual : Begin\n",
      "Predicted : Navigation \t Actual : Next\n",
      "Predicted : Hello \t Actual : Start\n",
      "Predicted : Navigation \t Actual : Begin\n",
      "Predicted : Connection \t Actual : Stop\n",
      "Predicted : Navigation \t Actual : Next\n",
      "Predicted : Navigation \t Actual : Next\n",
      "Predicted : Begin \t Actual : Begin\n",
      "Predicted : Start \t Actual : Web\n",
      "Predicted : Stop \t Actual : Hello\n",
      "Predicted : Web \t Actual : Stop\n",
      "Predicted : Previous \t Actual : Start\n",
      "Predicted : Stop \t Actual : Hello\n",
      "Predicted : Web \t Actual : Web\n",
      "Predicted : Hello \t Actual : Start\n",
      "Predicted : Navigation \t Actual : Previous\n",
      "Predicted : Start \t Actual : Connection\n",
      "Predicted : Choose \t Actual : Choose\n",
      "Predicted : Navigation \t Actual : Previous\n",
      "Predicted : Hello \t Actual : Start\n",
      "Predicted : Stop \t Actual : Stop\n",
      "Predicted : Navigation \t Actual : Begin\n",
      "Predicted : Hello \t Actual : Start\n",
      "Predicted : Navigation \t Actual : Next\n",
      "Predicted : Navigation \t Actual : Next\n",
      "Predicted : Navigation \t Actual : Begin\n",
      "Predicted : Choose \t Actual : Choose\n",
      "Predicted : Choose \t Actual : Choose\n",
      "Predicted : Navigation \t Actual : Next\n",
      "Predicted : Navigation \t Actual : Navigation\n",
      "Predicted : Navigation \t Actual : Begin\n",
      "Predicted : Connection \t Actual : Web\n",
      "Predicted : Hello \t Actual : Previous\n",
      "Predicted : Navigation \t Actual : Begin\n",
      "Predicted : Hello \t Actual : Navigation\n",
      "Predicted : Start \t Actual : Connection\n",
      "Predicted : Previous \t Actual : Previous\n",
      "Predicted : Connection \t Actual : Choose\n",
      "Predicted : Start \t Actual : Navigation\n",
      "Predicted : Hello \t Actual : Connection\n",
      "Predicted : Navigation \t Actual : Previous\n",
      "Predicted : Stop \t Actual : Choose\n",
      "Predicted : Navigation \t Actual : Navigation\n",
      "Predicted : Hello \t Actual : Start\n",
      "Predicted : Hello \t Actual : Previous\n",
      "Predicted : Stop \t Actual : Stop\n",
      "Predicted : Stop \t Actual : Hello\n",
      "Predicted : Navigation \t Actual : Navigation\n",
      "Predicted : Stop \t Actual : Hello\n",
      "Predicted : Choose \t Actual : Choose\n",
      "Predicted : Previous \t Actual : Hello\n",
      "Predicted : Choose \t Actual : Choose\n",
      "Predicted : Hello \t Actual : Connection\n",
      "Predicted : Navigation \t Actual : Next\n",
      "Predicted : Start \t Actual : Web\n",
      "Predicted : Start \t Actual : Web\n",
      "Predicted : Hello \t Actual : Start\n",
      "Predicted : Navigation \t Actual : Connection\n",
      "Predicted : Stop \t Actual : Web\n",
      "Predicted : Stop \t Actual : Stop\n",
      "Predicted : Stop \t Actual : Stop\n",
      "Predicted : Start \t Actual : Connection\n",
      "Predicted : Hello \t Actual : Navigation\n",
      "Predicted : Stop \t Actual : Hello\n",
      "Predicted : Navigation \t Actual : Next\n",
      "Predicted : Navigation \t Actual : Navigation\n",
      "Predicted : Hello \t Actual : Start\n",
      "Predicted : Hello \t Actual : Previous\n",
      "Predicted : Connection \t Actual : Choose\n",
      "Predicted : Previous \t Actual : Hello\n",
      "Predicted : Stop \t Actual : Stop\n",
      "Predicted : Stop \t Actual : Hello\n",
      "Predicted : Navigation \t Actual : Navigation\n",
      "Predicted : Connection \t Actual : Connection\n",
      "Predicted : Stop \t Actual : Hello\n",
      "Predicted : Begin \t Actual : Begin\n",
      "Predicted : Start \t Actual : Web\n",
      "Predicted : Hello \t Actual : Start\n",
      "Predicted : Hello \t Actual : Start\n",
      "Predicted : Navigation \t Actual : Next\n",
      "Predicted : Navigation \t Actual : Next\n",
      "Accuracy = 0.28 on completely unseen data\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for p, a in zip(predicted_words, actual_words):\n",
    "    if p == a:\n",
    "        correct += 1\n",
    "    print(f\"Predicted : {p} \\t Actual : {a}\")\n",
    "\n",
    "accuracy = correct/len(actual_words)\n",
    "print(f\"Accuracy = {accuracy} on completely unseen data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
